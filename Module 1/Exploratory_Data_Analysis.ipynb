{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cRcrM1P-gJnW"
   },
   "source": [
    "# VADSTI 2024\n",
    "\n",
    "# Module 1: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Z2jcRKwUHqV"
   },
   "source": [
    "\n",
    "\n",
    "This notebook provides recipes for exploratory data analysis which is a critical step in any data science project. The goal of this workshop is to learn how to perform initial investigations of the data so as to discover patterns, to spot anomalies, to test hypothesis and to check assumptions with the help of summary statistics and graphical representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qjtmQIPqFGRD"
   },
   "source": [
    "## **I. Dataset**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7nwZ4CcggWNT"
   },
   "source": [
    "We will use the diabetes dataset from the National Institute of Diabetes and Digestive and Kidney Diseases. \n",
    "\n",
    "The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. \n",
    "\n",
    "**Study population:** Female patients over 21 years old of Pima Indian heritage.\n",
    "\n",
    "**Data dictionary:** The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables include the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
    "\n",
    "> - ***Pregnancies***: Number of times pregnant\n",
    "- ***Glucose:*** Plasma glucose concentration over 2 hours in an oral 0 glucose tolerance test\n",
    "- ***BloodPressure:*** Diastolic blood pressure (mm Hg)\n",
    "- ***SkinThickness:*** Triceps skin fold thickness (mm)\n",
    "- ***Insulin:*** 2-Hour serum insulin (mu U/ml)\n",
    "- ***BMI:*** Body mass index (weight in kg/(height in m)2)\n",
    "- ***DiabetesPedigreeFunction:*** Diabetes pedigree function (a function which scores likelihood of diabetes based on family history)\n",
    "- ***Age:*** Age (years)\n",
    "- ***Outcome:*** Class variable (0 if non-diabetic, 1 if diabetic)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Link to dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database/download)\n",
    "\n",
    "[Link to UCI Repository](https://archive.ics.uci.edu/ml/datasets/diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wD3cZUDBC9Ln"
   },
   "source": [
    "## **II. Reading and manipulating the data**\n",
    "\n",
    "In this section we will read the diabetes dataset into a Pandas dataframe. The primary two components of pandas are the Series and DataFrame. A Series is essentially a column, and a DataFrame is a multi-dimensional table made up of a collection of Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BaCkyg5CV5jF"
   },
   "source": [
    "### **1. Reading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install pandas\n",
    "!sudo -H pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrppFI0rmpT5"
   },
   "outputs": [],
   "source": [
    "# Importing pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data into a pandas dataframe: diabetes_df. The dataset diabetes.csv is located under the ./dataset folder\n",
    "diabetes_df = pd.read_csv('./datasets/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View top 10 rows of diabetes_df\n",
    "diabetes_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8KUCm-h1JZ7w"
   },
   "source": [
    "### **2. Initial invesitgation**\n",
    "\n",
    "Let's perform initial investigations of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zrIZhZQ6h5rs",
    "outputId": "c3b3ca47-663a-4db3-9f92-9ba42786c031"
   },
   "outputs": [],
   "source": [
    "#What's the shape of our dataframe? How many rows? How many columns?\n",
    "diabetes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "AFrrFg87iCPQ",
    "outputId": "29624ed1-2fed-401d-a2f0-15762bc7a63b"
   },
   "outputs": [],
   "source": [
    "#Dataframe Columns\n",
    "diabetes_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "D43XQl2Mzw3R",
    "outputId": "05d662bc-e4a3-4943-e8a4-24efb54d0ae0"
   },
   "outputs": [],
   "source": [
    "#Column types\n",
    "diabetes_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "4pjWl-AtiVwj",
    "outputId": "1aa2d386-a541-4a90-8db0-37a295ee0761"
   },
   "outputs": [],
   "source": [
    "#Use .describe() on the dataframe to get a description of the dataframe\n",
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "EgD4S7QQ7gr_",
    "outputId": "eafefdf7-f7fe-4ebc-8b7e-ab1b800a5a1d"
   },
   "outputs": [],
   "source": [
    "#Use .info() on the dataframe to get a summary of the columns\n",
    "diabetes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3tFvGcF7Vijj",
    "outputId": "e8bdf951-2c76-4aa2-cb96-3c9dbef02e1a"
   },
   "outputs": [],
   "source": [
    "#What's the count breakdown of the Outcome variable\n",
    "diabetes_df.Outcome.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Table 1: Baseline charcteristics of the study population**\n",
    "\n",
    "When working with any patient dataset, it is important to understand the baseline characteristics of your study population. In this section, we will generate ``Table 1``, i.e., patient baseline characteristics table commonly found in biomedical research papers.\n",
    "\n",
    "We will use the tableone python package inspired by the R package with a same name. The tableone package can summarize both continuous and categorical variables mixed within one table. Categorical variables can be summarized as counts and/or percentages. Continuous variables can be summarized in the “normal” way (means and standard deviations) or “nonnormal” way (medians and interquartile ranges).\n",
    "\n",
    "The table one package can be found here: https://pypi.org/project/tableone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install the package\n",
    "!sudo -H pip3 install tableone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tableone\n",
    "from tableone import TableOne\n",
    "cols = ['Age', 'BMI','Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'DiabetesPedigreeFunction']\n",
    "\n",
    "#Use TableOne(data,columns,groupby) function to generate Table 1\n",
    "mytable = TableOne(diabetes_df,columns=cols,groupby=['Outcome'],nonnormal=nonnormal, pval=True,htest_name=True)\n",
    "mytable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDGmhwXhYbBG"
   },
   "source": [
    "### **4. Missing data**\n",
    "\n",
    "When working with any dataset, you’ll most likely encounter missing or null values, which are essentially placeholders for non-existent values. Most commonly you'll see Python's ``None`` or NumPy's ``np.nan``, each of which are handled differently in some situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "5Wmdi41duTjn",
    "outputId": "43312a5e-b4d1-4292-9351-99577dc60d1b"
   },
   "outputs": [],
   "source": [
    "#Let's print how many missing values per column\n",
    "diabetes_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCQZaQ18c1Yp"
   },
   "source": [
    "Let's visualize the missingness in our dataframe. We will use the ``missingno`` package  provides a small toolset of flexible and easy-to-use missing data visualizations and utilities that allows you to get a quick visual summary of the completeness (or lack thereof) of your dataset. \n",
    "\n",
    "Pip install missingno to get started. [Github link](https://github.com/ResidentMario/missingno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "colab_type": "code",
    "id": "Ep0gRAEwZPpJ",
    "outputId": "3c732f65-0495-41a5-8c88-b8c2d276abe7"
   },
   "outputs": [],
   "source": [
    "#install missingno package\n",
    "!sudo -H pip3 install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import missingno package and use msno as the shorthand\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bar Chart** \n",
    "`msno.bar` is a simple visualization of nullity by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "lv0qyAlifgiR"
   },
   "outputs": [],
   "source": [
    "#use the msno.bar to plot a bar chart of nullity by column\n",
    "msno.bar(diabetes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missingness Matrix:** \n",
    "The `msno.matrix` nullity matrix is a data-dense display which lets you quickly visually pick out patterns in data completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize missingness per column using the msno.matrix function\n",
    "msno.matrix(diabetes_df,figsize=(18,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling missing data\n",
    "\n",
    "Understanding the reasons why data are missing is important for handling the remaining data correctly. If values are missing completely at random, the data sample is likely still representative of the population. But if the values are missing systematically, analysis may be biased. There are 3 types of missing data:\n",
    "\n",
    "- ***Missing completely at random (MCAR)*** The propensity for a data point to be missing is completely random. The missing data are just a random subset of the data.\n",
    "\n",
    "- ***Missing at random (MAR)*** Missing at Random means  the propensity for a data point to be missing is not related to the missing data, but it is related to some of the observed data. An example is that males are less likely to fill in a depression survey but this has nothing to do with their level of depression, after accounting for maleness. \n",
    "\n",
    "- ***Missing not at random (MNAR)*** (also known as nonignorable nonresponse) is data that is neither MAR nor MCAR (i.e. the value of the variable that's missing is related to the reason it's missing). To extend the previous example, this would occur if men failed to fill in a depression survey because of their level of depression.\n",
    "\n",
    "Generally speaking, there are three main approaches to handle missing data: \n",
    "\n",
    "> - ***Omission***: where samples with invalid data are discarded from further analysis,\n",
    "- ***Imputation:*** where values are filled in the place of missing data, \n",
    "- ***Analysis:*** by directly applying methods unaffected by the missing values. \n",
    "\n",
    "The choice of which methods to use is based on the use case and how the data was collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "evDteETl5AWQ",
    "outputId": "5ebf525d-c029-4aff-8e6d-57b9e5bdeee8"
   },
   "outputs": [],
   "source": [
    "#Listwise deletion (row deletion)\n",
    "diabetes_cc = diabetes_df.dropna()\n",
    "diabetes_cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns with missing data\n",
    "diabetes_omission = diabetes_df.dropna(axis=1)\n",
    "diabetes_omission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OoLNO_CTwgyV"
   },
   "outputs": [],
   "source": [
    "#Impute using a constant\n",
    "diabetes_constant = diabetes_df.fillna(0)\n",
    "diabetes_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "46UOdTGc7AJA",
    "outputId": "612c940b-d29b-4109-c5ae-48f0af0964b4"
   },
   "outputs": [],
   "source": [
    "#Imputing using mean\n",
    "diabetes_mean = diabetes_df.fillna(diabetes_df.mean())\n",
    "diabetes_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "fxo5N8ikyn3D",
    "outputId": "44ae321c-a19b-4f22-be01-916d661e906d"
   },
   "outputs": [],
   "source": [
    "#Check the dataframe for missing data\n",
    "diabetes_final.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d8CD_sGx6UZb"
   },
   "source": [
    "### **6. Filtering and transofrming the data**\n",
    "\n",
    "Based on the data use case, you might need to perform data transformations including subseting or filtering the data, creating categorical variables, or applying certain data manipulations. In this section, we review some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jbQPIsZB_f53"
   },
   "source": [
    "**Creating an age group variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "7GaZCYNOyUJN",
    "outputId": "a38f556b-fbb5-4c4d-b2f6-559a88c8b879"
   },
   "outputs": [],
   "source": [
    "#Use the describe() function to review a summary of the Age column\n",
    "diabetes_final['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "HpksgywV1j7G",
    "outputId": "91a19151-78fa-40a4-fe35-05e72e3d96bd"
   },
   "outputs": [],
   "source": [
    "#Histogram of age variable\n",
    "diabetes_df.Age.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "VO3aJKvfylFK",
    "outputId": "5bca2fa5-229a-4700-de7c-ec2beec3a07e"
   },
   "outputs": [],
   "source": [
    "#Binning the Age column using pd.cut function\n",
    "import numpy as np\n",
    "\n",
    "diabetes_final['age_group'] = pd.cut(diabetes_final['Age'], bins=[21,45,65,np.inf], labels=['21-44', '45-64', '65>'],right=False)\n",
    "diabetes_final.age_group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5GXfSztB_v2O"
   },
   "source": [
    "**Filtering data**\n",
    "\n",
    "Filtering data using conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "id": "YrswBKSG4pMp",
    "outputId": "165996c0-7334-4650-947b-d876a05fcd26"
   },
   "outputs": [],
   "source": [
    "#diabetes_final[diabetes_final['age_group'] == \"65>\"]\n",
    "#diabetes_final[(diabetes_final['Age'] > 65)]\n",
    "#diabetes_final[(diabetes_final['Age'] > 65) | (diabetes_final['Age']<45) ]\n",
    "#diabetes_final[(diabetes_final['Age'] > 65) & (diabetes_final['bmi']>30) ]\n",
    "#diabetes_final[(diabetes_final['Age'] > diabetes_final['Age'].quantile(0.25))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHW_zyMF8Rw4"
   },
   "source": [
    "**Using the apply function**\n",
    "\n",
    "We will write a function to group BMI and use the 'map' to generate a new bmi_group column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yg2EVyDf8QPs"
   },
   "outputs": [],
   "source": [
    "# Function takes as an input the bmi and output a bmi group \n",
    "# x<18.5 -> Unhealthy low\n",
    "# x>=18.5 and x<25 -> Healthy\n",
    "# x>=25 and x<30 -> Overweight\n",
    "# x>=30 -> Obese\n",
    "\n",
    "def bmi_groups(x):\n",
    "    if x <18.5:\n",
    "        return \"Unhealthy Low\"\n",
    "    if x>=18.5 and x<25:\n",
    "        return \"Healthy\"\n",
    "    if x>=25 and x<30:\n",
    "        return \"Overweight\"\n",
    "    if x>=30:\n",
    "        return \"Obese\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1VLAzEJLAllE"
   },
   "source": [
    "Now let's use the use the function to add a bmi_category column to our dataframe. We will use `.map()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "8Nkxn1HIIvSu",
    "outputId": "552d635a-98c3-4948-96e5-8590004e2752"
   },
   "outputs": [],
   "source": [
    "diabetes_final[\"bmi_category\"] = diabetes_final[\"BMI\"].map(bmi_groups)\n",
    "diabetes_final.bmi_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4wuWuqNUJ6L"
   },
   "source": [
    "## **III. Data Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "td8XDjJfJViH"
   },
   "source": [
    "\n",
    "Let’s also look at how many people in the dataset are diabetic and how many are not. Below is the barplot of the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "U5YT8vKPTzEq",
    "outputId": "718d6d42-b812-4dcd-ea75-366c69f06564"
   },
   "outputs": [],
   "source": [
    "#Use the seaborn package to plot bar plots of the bmi_category variable\n",
    "import seaborn as sns\n",
    "ax = sns.countplot(x=\"bmi_category\", data=diabetes_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use matplotlib package to plot bar plot of the bmi_category variable\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(diabetes_final.bmi_category)\n",
    "plt.bar(counter.keys(),counter.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pandas vizualisation to plot bar plot of the bmi_category variable\n",
    "diabetes_final.bmi_category.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cnzQmP35HWKi"
   },
   "source": [
    "Let's plot the reltionship between age and bmi or age and other variables using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "4VxecZKyHVDW",
    "outputId": "fb9bfbc5-0801-4e53-abea-838ada1828df"
   },
   "outputs": [],
   "source": [
    "#Use pandas vizualisation to plot scatter plot of Age and BMI\n",
    "diabetes_final.plot(kind='scatter', x='Age', y='BMI', title='Age vs BMI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IV. Feature Selection**\n",
    "\n",
    "Feature selection is crucial in enhancing model performance by focusing on relevant attributes. It involves identifying and utilizing the most informative features, streamlining the analysis process. \n",
    "\n",
    "Feature extraction is essential in machine learning as it reduces data dimensionality, improving model efficiency and performance. \n",
    "\n",
    "Techniques for feature selection vary, including statistical tests, model-based approaches, and iterative methods, each offering unique advantages in simplifying datasets and improving predictive accuracy. Here are some ways in which we can perform feafure selection\n",
    "\n",
    "### **a) Correlations**\n",
    "\n",
    "\n",
    "We measure correlation of two numerical variables to find an insight about their relationships. On a dataset with many attributes, the set of correlation values between pairs of its attributes form a matrix which is called a correlation matrix.\n",
    "\n",
    "Correlation can be used in feature extraction by identifying and retaining features that are highly correlated with the target variable, while removing features that are highly correlated with each other. This reduces redundancy and focuses the model on features most relevant to predicting the outcome, improving model performance and interpretability.\n",
    "\n",
    "We can use pandas `.corr` function to generate correlations between columns or a correlation matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the correlation between Age and BMI\n",
    "column_1 = diabetes_df[\"BMI\"]\n",
    "column_2 = diabetes_df[\"Age\"]\n",
    "correlation = column_1.corr(column_2)\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Pearson correlation to generate a \n",
    "corr = diabetes_df.corr(method='pearson')\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)#.to_excel('correlation_matrix_pearson.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the lower triangle of the correlation heatmap using Seaborn\n",
    "#look at feature correlations\n",
    "corr = diabetes_df.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "#make the heatmap plot\n",
    "plt.figure(figsize=(16,9))\n",
    "sns.heatmap(corr, mask=mask, annot = True,cmap='coolwarm', square=True)#, vmax=1, vmin=-1,center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.tight_layout()\n",
    "plt.savefig('heatmap.png', dpi=250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b) Variance**\n",
    "\n",
    "Variance can be used for feature selection by identifying and retaining features that have high variance, as they are likely to contain more information than features with low variance. Features with low variance may not significantly impact the model's predictions and can be considered for removal. This approach helps in reducing the dimensionality of the dataset, leading to improved model performance and computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we check to see what the variance for each columns look like.\n",
    "diabetes_df.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **V. Data Transformation**\n",
    "\n",
    "### a) Data Normalization\n",
    "\n",
    "Data normalization in Pandas involves scaling numerical columns to a common scale without distorting differences in the ranges of values. This is crucial for algorithms that assume data is centered around 0 and scaled uniformly, like K-Means clustering or principal component analysis (PCA). To normalize data, you can use the `MinMaxScaler` from `sklearn.preprocessing` for min-max normalization or `StandardScaler` for z-score normalization. Apply these scalers to your DataFrame columns to transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalization\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(diabetes_df), columns=diabetes_df.columns)\n",
    "\n",
    "# Z-Score Normalization\n",
    "scaler = StandardScaler()\n",
    "df_standardized = pd.DataFrame(scaler.fit_transform(diabetes_df), columns=diabetes_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **VI. Data Splitting**\n",
    "\n",
    "\n",
    "Data splitting involves dividing a dataset into separate sets to train and evaluate a machine learning model, typically into training, and test sets. This approach helps to assess the model's performance and generalization to new, unseen data, ensuring it learns patterns rather than memorizing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes_df, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **VII. Generate a data exploration report**\n",
    "\n",
    "\n",
    "Let's use pandas_profiling library to generate a report for the variables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install pandas-profiling\n",
    "!sudo -H pip3 install -U pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "VmZUHGyjQpsg",
    "outputId": "0c6ab146-4d59-4654-8a9f-859d7bd54664"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "\n",
    "# Reading data into a pandas dataframe: diabetes_df\n",
    "diabetes_df = pd.read_csv('./datasets/diabetes.csv')\n",
    "\n",
    "profile = pandas_profiling.ProfileReport(diabetes_df)\n",
    "profile.to_file(\"./exports/profiling_report.html\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Workshop 1 - Exploratory Data Analysis",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
